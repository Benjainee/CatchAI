CatchAI â€“ Copiloto Conversacional sobre Documentos

Copiloto que permite subir hasta 5 PDFs y hacer preguntas en lenguaje natural sobre su contenido.
Responde de forma contextual (RAG) y ofrece resumen y clasificaciÃ³n por temas.
UI en Streamlit y contenerizaciÃ³n con Docker + docker-compose.

ğŸš€ Levantar el entorno (Docker + docker-compose)

ğŸ’¡ DÃ³nde ejecutar los comandos: puedes usar la terminal integrada de VS Code (PowerShell/CMD/Bash). No es necesario abrir PowerShell por separado.
ğŸªŸ En Windows, asegÃºrate de que Docker Desktop estÃ¡ iniciado y con WSL2 habilitado.

0) Prerrequisitos

    Docker Desktop (WSL2 habilitado si estÃ¡s en Windows).

    OpenAI API Key con cuota activa.

1) Variables de entorno

Crea tu archivo .env a partir del ejemplo:

    # Linux/Mac
    cp .env.example .env

    # Windows PowerShell (tambiÃ©n funciona desde la terminal de VS Code)
    Copy-Item .env.example .env


Edita .env y coloca tu clave:

    OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXXXXXX   # obligatorio (no subir al repo)
    OPENAI_MODEL=gpt-4o-mini                     # opcional (default gpt-4o-mini)


2) Build & Run
    docker compose build --no-cache
    docker compose up


Abre: http://localhost:8501

Comandos Ãºtiles

    docker compose up -d         # ejecutar en segundo plano
    docker compose logs -f web   # ver logs del servicio 'web'
    docker compose down          # bajar servicios

ğŸ§ª Uso

    1. Sube hasta 5 PDFs en la barra lateral.

    2. Cada PDF se indexa (verÃ¡s â€œIndexandoâ€¦ (Xs)â€); cuando pase a Listo, ya puedes preguntar.

    3. Escribe tu pregunta en espaÃ±ol (la respuesta cita pÃ¡ginas cuando es posible).

Acciones opcionales:

    ğŸ§¾ Resumen del PDF activo (6â€“8 viÃ±etas, tÃ©cnico, pÃ¡ginas cuando aplica).
    ğŸ§© Clasificar por temas (JSON con { tema, palabras_clave, paginas, resumen }).
    ğŸ§¹ Limpieza: botÃ³n â€œVaciar base vectorialâ€ en la UI (borra ./chroma_db) o elimina la carpeta manualmente.


ğŸ§± Arquitectura del sistema
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Streamlit           â”‚  UI (chat + botones + estado)
â”‚  - Uploader (â‰¤5 PDFs)          â”‚
â”‚  - Estado por PDF (Index/Ready)â”‚
â”‚  - Acciones: QA/Resumen/Clasif.â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ (tareas)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OrquestaciÃ³n           â”‚
â”‚  LangChain:                    â”‚
â”‚  - PyPDFLoader (parseo)        â”‚
â”‚  - RecursiveTextSplitter       â”‚
â”‚  - HuggingFaceEmbeddings       â”‚
â”‚  - Chroma (vector store)       â”‚
â”‚  - Retriever (MMR)             â”‚
â”‚  - RetrievalQA + prompts       â”‚
â”‚  - Ejecutores (index/QA)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ (contexto)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LLM               â”‚
â”‚  OpenAI (langchain-openai)     â”‚
â”‚  - Modelo: gpt-4o-mini (def.)  â”‚
â”‚  - Respuestas en espaÃ±ol       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Detalles clave

. Split: chunk_size=900, chunk_overlap=180 para buen recall.
. Retriever (MMR): k=8, fetch_k=50, lambda_mult=0.5 (cobertura diversa).
. Persistencia: carpeta por PDF dentro de ./chroma_db (limpieza granular).
. Ejecutores:
    .Indexado en serie (evita locks en Windows).
    .QA/Resumen/Clasificar en paralelo (no escribe en disco).
Auto-Refresh 1s: timers y estados se actualizan en vivo.


ğŸ§  Flujo conversacional (RAG)

    1. Upload â†’ lectura con PyPDFLoader.
    2. Split â†’ RecursiveCharacterTextSplitter (metadatos incluyen nombre del archivo y pÃ¡gina).
    3. VectorizaciÃ³n â†’ HuggingFaceEmbeddings â†’ Chroma (colecciÃ³n por PDF).
    4. QA â†’ Retriever (MMR) â†’ RetrievalQA con prompt instructivo
    (responde solo con el contexto; cita pÃ¡ginas cuando puede).

Extras:
    . Resumen: sÃ­ntesis tÃ©cnica en 6â€“8 viÃ±etas.
    . Clasificar: JSON de temas, keywords y pÃ¡ginas.

ğŸ§° Variables de entorno:

    Variable	Obligatoria	Default	DescripciÃ³n
        . OPENAI_API_KEY	SÃ­	â€”	API key de OpenAI
        . OPENAI_MODEL	No	gpt-4o-mini	Modelo de chat (puedes cambiarlo)

Puedes usar otro modelo compatible con langchain-openai si el evaluador lo prefiere.


ğŸ“¦ Estructura del repo
.
â”œâ”€ app.py
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ .dockerignore
â”œâ”€ .env.example            # ejemplo (sin credenciales)
â””â”€ chroma_db/              # (se crea en runtime; se puede limpiar)


Sugerido en .gitignore:

    .env
    chroma_db/
    __pycache__/
    .venv/

ğŸ§  JustificaciÃ³n de elecciones tÃ©cnicas

    1. LangChain: facilita la orquestaciÃ³n (loaders, retrievers, prompts) y cumplir el requisito de â€œflujo extensibleâ€.
    2. Chroma: simple, local y eficiente para POC; persistencia por documento mejora trazabilidad y limpieza.
    3. HuggingFace Embeddings (MiniLM L6 v2): buena relaciÃ³n calidad/velocidad sin costo por token.
    4. OpenAI (ChatOpenAI): robusto para QA/Resumen en espaÃ±ol; configuraciÃ³n simple vÃ­a .env.
    5. Streamlit: prototipado rÃ¡pido de UI con manejo de estado; auto-refresh mejora UX.

âš ï¸ Limitaciones actuales

    1. Sin OCR para PDFs escaneados (solo texto extraÃ­ble).
    2. Citas de pÃ¡ginas desde metadatos del loader (sin resaltado exacto en el PDF).
    3. Sin reranking especÃ­fico (solo MMR).
    4. Dependencia de cuota de OpenAI (error 429 si no hay crÃ©dito).
    5. Contexto limitado por el mÃ¡ximo de tokens del modelo.


ğŸ—ºï¸ Roadmap (mejoras futuras)

    1. ğŸ” OCR (pytesseract + layout) para PDFs escaneados.
    2. ğŸª„ Reranking (Cohere Rerank / LLM-as-reranker) para mayor precisiÃ³n.
    3. âš–ï¸ ComparaciÃ³n multi-PDF con botÃ³n en UI (la tarea estÃ¡ implementada; activar acciÃ³n dedicada).
    4. ğŸŒ Embeddings multilingÃ¼es (all-mpnet-base-v2 u OpenAI embeddings).
    5. ğŸ§° Backend FastAPI (API, auth, logging).
    6. â˜ï¸ Despliegue Cloud (imagen pÃºblica y compose listo).
    7. ğŸ“ Citas enriquecidas (resalte de spans en el PDF y enlaces a pÃ¡ginas).


ğŸ§ª Desarrollo local sin Docker (opcional)

    python -m venv .venv

    # Windows (PowerShell)
    .\.venv\Scripts\Activate.ps1
    # Linux/Mac
    source .venv/bin/activate

    pip install -r requirements.txt
    cp .env.example .env   # agrega tu OPENAI_API_KEY
    streamlit run app.py
    
    Abrir: http://localhost:8501


ğŸ› ï¸ Troubleshooting

    1. 429 / insufficient_quota: revisa plan/billing de OpenAI o usa un modelo mÃ¡s barato.
    2. 401 (unauthorized): verifica OPENAI_API_KEY en .env.
    3. No se ve la UI: puerto ocupado; cambia mapeo en docker-compose.yml (por ejemplo 8502:8501).
    4. Index se queda â€œen cursoâ€: usa â€œVaciar base vectorialâ€ y vuelve a subir; hay timeout de seguridad.
    5. Windows/WSL2/Docker: confirma Docker Desktop corriendo y suficiente espacio en disco.